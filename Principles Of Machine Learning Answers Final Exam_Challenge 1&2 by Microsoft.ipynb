{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Principles Of Machine Learning Answers Final Exam_Challenge 1&2 by Microsoft.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"Z-wwfJ9EHP3C","colab_type":"text"},"cell_type":"markdown","source":["# Challenge Overview\n","\n","In 1998, the Adventure Works Cycles company collected a large volume of data about their existing customers, including demographic features and information about purchases they have made. The company is particularly interested in analyzing customer data to determine any apparent relationships between demographic features known about the customers and the likelihood of a customer purchasing a bike. Additionally, the analysis should endeavor to determine whether a customer's average monthly spend with the company can be predicted from known customer characteristics.\n","\n","In this project, you must tackle three challenges:\n","\n","Challenge 1: Explore the data and gain some insights into Adventure Works customer characteristics and purchasing behavior.\n","\n","Challenge 2: Build a classification model to predict customer purchasing behavior.\n","\n","Challenge 3: Build a regression model to predict customer purchasing behavior."]},{"metadata":{"id":"J--idURXm5h6","colab_type":"text"},"cell_type":"markdown","source":["# Challenge 1: Data Exploration\n","\n","To complete this challenge:\n","\n","1.   Download the Adventure Works data files - see previous unit.\n","\n","2.   Clean the data by replacing any missing values and removing duplicate rows. In this dataset, each customer is identified by a unique customer ID. The most recent version of a duplicated record should be retained.\n","\n","3.   Explore the data by calculating summary and descriptive statistics for the features in the dataset, calculating correlations between features, and creating data visualizations to determine apparent relationships in the data.\n","\n","4.   Based on your analysis of the customer data **after** removing all duplicate customer records, evaluate the BikeBuyer and AveMonthSpend metrics"]},{"metadata":{"id":"JA2Q9FCTIBAQ","colab_type":"text"},"cell_type":"markdown","source":["## Meeting Challenge 1\n","\n","First things first - load the packages required as well as the datasets!!"]},{"metadata":{"id":"EKRyFGnDIqNm","colab_type":"code","outputId":"7183c215-9f24-4ae3-b40d-55104010f0f7","executionInfo":{"status":"ok","timestamp":1552913961424,"user_tz":-180,"elapsed":1686,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/","height":733}},"cell_type":"code","source":["#Loading required packages\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","\n","#Loading required datasets\n","CustomerDemographics = pd.read_csv('https://raw.githubusercontent.com/CeeThinwa/DataScienceLearning/master/AdvWorksCusts.csv')\n","AverageMonthlySpend = pd.read_csv('https://raw.githubusercontent.com/CeeThinwa/DataScienceLearning/master/AW_AveMonthSpend.csv')\n","BikeBuyer = pd.read_csv('https://raw.githubusercontent.com/CeeThinwa/DataScienceLearning/master/AW_BikeBuyer.csv')\n","\n","#and additional test dataset for Challenge 2\n","TestData = pd.read_csv('https://raw.githubusercontent.com/CeeThinwa/DataScienceLearning/master/AW_test.csv')\n","\n","#Viewing the data\n","print(CustomerDemographics.shape)\n","print(AverageMonthlySpend.shape)\n","print(BikeBuyer.shape)\n","\n","#Viewing the datatypes within each dataset\n","print (' ')\n","print('Customer Demographics DataTypes')\n","print(CustomerDemographics.dtypes)\n","print(' ')\n","print('Average Monthly Spend DataTypes')\n","print(AverageMonthlySpend.dtypes)\n","print(' ')\n","print('Bike Buyer DataTypes')\n","print(BikeBuyer.dtypes)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(16519, 23)\n","(16519, 2)\n","(16519, 2)\n"," \n","Customer Demographics DataTypes\n","CustomerID               int64\n","Title                   object\n","FirstName               object\n","MiddleName              object\n","LastName                object\n","Suffix                  object\n","AddressLine1            object\n","AddressLine2            object\n","City                    object\n","StateProvinceName       object\n","CountryRegionName       object\n","PostalCode              object\n","PhoneNumber             object\n","BirthDate               object\n","Education               object\n","Occupation              object\n","Gender                  object\n","MaritalStatus           object\n","HomeOwnerFlag            int64\n","NumberCarsOwned          int64\n","NumberChildrenAtHome     int64\n","TotalChildren            int64\n","YearlyIncome             int64\n","dtype: object\n"," \n","Average Monthly Spend DataTypes\n","CustomerID       int64\n","AveMonthSpend    int64\n","dtype: object\n"," \n","Bike Buyer DataTypes\n","CustomerID    int64\n","BikeBuyer     int64\n","dtype: object\n"],"name":"stdout"}]},{"metadata":{"id":"_3HCKMA0TtRD","colab_type":"text"},"cell_type":"markdown","source":["Next, we clean the AverageMonthlySpend dataset by removing duplicate rows and removing missing values..."]},{"metadata":{"id":"s8mj-JEuYStJ","colab_type":"code","outputId":"48067263-c196-4503-8b8d-d039eb077721","executionInfo":{"status":"ok","timestamp":1552913962493,"user_tz":-180,"elapsed":2630,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/","height":447}},"cell_type":"code","source":["#This involves first identifying the initial shape of the dataframe\n","print(AverageMonthlySpend.shape)\n","\n","#then applying the dropna method to the data\n","AverageMonthlySpend.dropna()\n","\n","#and checking for any duplicates\n","AverageMonthlySpend.drop_duplicates(['CustomerID'], keep = 'last')\n","\n","#and finally checking the final shape of the dataframe\n","print(AverageMonthlySpend.shape)\n","\n","#Knowing this, we can then identify the descriptive stats for each column!\n","print(' ')\n","print('**Median Row**')\n","print(AverageMonthlySpend.median())\n","print(' ')\n","AverageMonthlySpend.describe()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(16519, 2)\n","(16519, 2)\n"," \n","**Median Row**\n","CustomerID       20221.0\n","AveMonthSpend       68.0\n","dtype: float64\n"," \n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CustomerID</th>\n","      <th>AveMonthSpend</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>16519.000000</td>\n","      <td>16519.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>20234.225195</td>\n","      <td>72.405957</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>5342.515987</td>\n","      <td>27.285370</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>11000.000000</td>\n","      <td>22.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>15604.500000</td>\n","      <td>52.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>20221.000000</td>\n","      <td>68.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>24860.500000</td>\n","      <td>84.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>29482.000000</td>\n","      <td>176.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         CustomerID  AveMonthSpend\n","count  16519.000000   16519.000000\n","mean   20234.225195      72.405957\n","std     5342.515987      27.285370\n","min    11000.000000      22.000000\n","25%    15604.500000      52.000000\n","50%    20221.000000      68.000000\n","75%    24860.500000      84.000000\n","max    29482.000000     176.000000"]},"metadata":{"tags":[]},"execution_count":2}]},{"metadata":{"id":"b03-tPxKhQtd","colab_type":"text"},"cell_type":"markdown","source":["Next, we repeat the cleaning process for the BikeBuyer dataset, checking the shape of the dataset to see if we have lost any rows...."]},{"metadata":{"id":"5boIvYvZkhtP","colab_type":"code","outputId":"ca106054-edd5-4808-96f7-b109730a94d0","executionInfo":{"status":"ok","timestamp":1552913962503,"user_tz":-180,"elapsed":2562,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["#Again, first we identify the initial shape of the dataframe\n","print(BikeBuyer.shape)\n","\n","#apply the dropna method to the data\n","BikeBuyer.dropna()\n","\n","#and checking for any duplicates\n","BikeBuyer.drop_duplicates(['CustomerID'], keep = 'last')\n","\n","#and finally checking the final shape of the dataframe\n","print(BikeBuyer.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(16519, 2)\n","(16519, 2)\n"],"name":"stdout"}]},{"metadata":{"id":"_lJ40E1ooLQZ","colab_type":"text"},"cell_type":"markdown","source":["We can finally clean and prepare the CustomerDemographics dataset for further analysis..."]},{"metadata":{"id":"vVmV2Mllonqv","colab_type":"code","outputId":"c9daa9eb-4450-4e6c-bb5c-41d480a7f1ac","executionInfo":{"status":"ok","timestamp":1552913962515,"user_tz":-180,"elapsed":2498,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/","height":201}},"cell_type":"code","source":["#For one last time, we first identify the initial shape of the dataframe\n","print(CustomerDemographics.shape)\n","\n","#and check for any duplicates\n","CustomerDemographics.drop_duplicates(['CustomerID'], keep = 'last')\n","\n","#finally, we can check the final shape of the dataframe\n","print(CustomerDemographics.shape)\n","print(' ')\n","\n","#To identify the median YearlyIncome for each occupation category, we first group by the Occupation series and then find the corresponding medians of Yearly Income\n","print(CustomerDemographics.groupby(['Occupation'])['YearlyIncome'].median())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(16519, 23)\n","(16519, 23)\n"," \n","Occupation\n","Clerical           49387.0\n","Management        118780.0\n","Manual             21722.5\n","Professional       99046.0\n","Skilled Manual     66481.0\n","Name: YearlyIncome, dtype: float64\n"],"name":"stdout"}]},{"metadata":{"id":"vWvel-MhxGQc","colab_type":"text"},"cell_type":"markdown","source":["Now that all 3 datasets are cleaned, it is time to merge them into a new dataframe that we can further analyse."]},{"metadata":{"id":"vMRWG3LkyNqI","colab_type":"code","outputId":"cbf23801-e261-4b87-9719-7b25454e99bd","executionInfo":{"status":"ok","timestamp":1552913962525,"user_tz":-180,"elapsed":2471,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/","height":586}},"cell_type":"code","source":["#First things first, we join the Average Monthly Spend to the Customer Demographics Data\n","IntegratedCustomerData = CustomerDemographics.join(AverageMonthlySpend['AveMonthSpend'])\n","\n","#Next, we repeat the join so as to add the Bike Buyer series to the new integrated dataset\n","IntegratedCustomerData = IntegratedCustomerData.join(BikeBuyer['BikeBuyer'])\n","\n","IntegratedCustomerData.head(10)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CustomerID</th>\n","      <th>Title</th>\n","      <th>FirstName</th>\n","      <th>MiddleName</th>\n","      <th>LastName</th>\n","      <th>Suffix</th>\n","      <th>AddressLine1</th>\n","      <th>AddressLine2</th>\n","      <th>City</th>\n","      <th>StateProvinceName</th>\n","      <th>...</th>\n","      <th>Occupation</th>\n","      <th>Gender</th>\n","      <th>MaritalStatus</th>\n","      <th>HomeOwnerFlag</th>\n","      <th>NumberCarsOwned</th>\n","      <th>NumberChildrenAtHome</th>\n","      <th>TotalChildren</th>\n","      <th>YearlyIncome</th>\n","      <th>AveMonthSpend</th>\n","      <th>BikeBuyer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11000</td>\n","      <td>NaN</td>\n","      <td>Jon</td>\n","      <td>V</td>\n","      <td>Yang</td>\n","      <td>NaN</td>\n","      <td>3761 N. 14th St</td>\n","      <td>NaN</td>\n","      <td>Rockhampton</td>\n","      <td>Queensland</td>\n","      <td>...</td>\n","      <td>Professional</td>\n","      <td>M</td>\n","      <td>M</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>137947</td>\n","      <td>89</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11001</td>\n","      <td>NaN</td>\n","      <td>Eugene</td>\n","      <td>L</td>\n","      <td>Huang</td>\n","      <td>NaN</td>\n","      <td>2243 W St.</td>\n","      <td>NaN</td>\n","      <td>Seaford</td>\n","      <td>Victoria</td>\n","      <td>...</td>\n","      <td>Professional</td>\n","      <td>M</td>\n","      <td>S</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>101141</td>\n","      <td>117</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11002</td>\n","      <td>NaN</td>\n","      <td>Ruben</td>\n","      <td>NaN</td>\n","      <td>Torres</td>\n","      <td>NaN</td>\n","      <td>5844 Linden Land</td>\n","      <td>NaN</td>\n","      <td>Hobart</td>\n","      <td>Tasmania</td>\n","      <td>...</td>\n","      <td>Professional</td>\n","      <td>M</td>\n","      <td>M</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>91945</td>\n","      <td>123</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11003</td>\n","      <td>NaN</td>\n","      <td>Christy</td>\n","      <td>NaN</td>\n","      <td>Zhu</td>\n","      <td>NaN</td>\n","      <td>1825 Village Pl.</td>\n","      <td>NaN</td>\n","      <td>North Ryde</td>\n","      <td>New South Wales</td>\n","      <td>...</td>\n","      <td>Professional</td>\n","      <td>F</td>\n","      <td>S</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>86688</td>\n","      <td>50</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11004</td>\n","      <td>NaN</td>\n","      <td>Elizabeth</td>\n","      <td>NaN</td>\n","      <td>Johnson</td>\n","      <td>NaN</td>\n","      <td>7553 Harness Circle</td>\n","      <td>NaN</td>\n","      <td>Wollongong</td>\n","      <td>New South Wales</td>\n","      <td>...</td>\n","      <td>Professional</td>\n","      <td>F</td>\n","      <td>S</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>92771</td>\n","      <td>95</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>11005</td>\n","      <td>NaN</td>\n","      <td>Julio</td>\n","      <td>NaN</td>\n","      <td>Ruiz</td>\n","      <td>NaN</td>\n","      <td>7305 Humphrey Drive</td>\n","      <td>NaN</td>\n","      <td>East Brisbane</td>\n","      <td>Queensland</td>\n","      <td>...</td>\n","      <td>Professional</td>\n","      <td>M</td>\n","      <td>S</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>103199</td>\n","      <td>78</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>11006</td>\n","      <td>NaN</td>\n","      <td>Janet</td>\n","      <td>G</td>\n","      <td>Alvarez</td>\n","      <td>NaN</td>\n","      <td>2612 Berry Dr</td>\n","      <td>NaN</td>\n","      <td>Matraville</td>\n","      <td>New South Wales</td>\n","      <td>...</td>\n","      <td>Professional</td>\n","      <td>F</td>\n","      <td>S</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>84756</td>\n","      <td>54</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>11007</td>\n","      <td>NaN</td>\n","      <td>Marco</td>\n","      <td>NaN</td>\n","      <td>Mehta</td>\n","      <td>NaN</td>\n","      <td>942 Brook Street</td>\n","      <td>NaN</td>\n","      <td>Warrnambool</td>\n","      <td>Victoria</td>\n","      <td>...</td>\n","      <td>Professional</td>\n","      <td>M</td>\n","      <td>M</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>109759</td>\n","      <td>130</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>11008</td>\n","      <td>NaN</td>\n","      <td>Rob</td>\n","      <td>NaN</td>\n","      <td>Verhoff</td>\n","      <td>NaN</td>\n","      <td>624 Peabody Road</td>\n","      <td>NaN</td>\n","      <td>Bendigo</td>\n","      <td>Victoria</td>\n","      <td>...</td>\n","      <td>Professional</td>\n","      <td>F</td>\n","      <td>S</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>88005</td>\n","      <td>85</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>11009</td>\n","      <td>NaN</td>\n","      <td>Shannon</td>\n","      <td>C</td>\n","      <td>Carlson</td>\n","      <td>NaN</td>\n","      <td>3839 Northgate Road</td>\n","      <td>NaN</td>\n","      <td>Hervey Bay</td>\n","      <td>Queensland</td>\n","      <td>...</td>\n","      <td>Professional</td>\n","      <td>M</td>\n","      <td>S</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>106399</td>\n","      <td>74</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 25 columns</p>\n","</div>"],"text/plain":["   CustomerID Title  FirstName MiddleName LastName Suffix  \\\n","0       11000   NaN        Jon          V     Yang    NaN   \n","1       11001   NaN     Eugene          L    Huang    NaN   \n","2       11002   NaN      Ruben        NaN   Torres    NaN   \n","3       11003   NaN    Christy        NaN      Zhu    NaN   \n","4       11004   NaN  Elizabeth        NaN  Johnson    NaN   \n","5       11005   NaN      Julio        NaN     Ruiz    NaN   \n","6       11006   NaN      Janet          G  Alvarez    NaN   \n","7       11007   NaN      Marco        NaN    Mehta    NaN   \n","8       11008   NaN        Rob        NaN  Verhoff    NaN   \n","9       11009   NaN    Shannon          C  Carlson    NaN   \n","\n","          AddressLine1 AddressLine2           City StateProvinceName  \\\n","0      3761 N. 14th St          NaN    Rockhampton        Queensland   \n","1           2243 W St.          NaN        Seaford          Victoria   \n","2     5844 Linden Land          NaN         Hobart          Tasmania   \n","3     1825 Village Pl.          NaN     North Ryde   New South Wales   \n","4  7553 Harness Circle          NaN     Wollongong   New South Wales   \n","5  7305 Humphrey Drive          NaN  East Brisbane        Queensland   \n","6        2612 Berry Dr          NaN     Matraville   New South Wales   \n","7     942 Brook Street          NaN    Warrnambool          Victoria   \n","8     624 Peabody Road          NaN        Bendigo          Victoria   \n","9  3839 Northgate Road          NaN     Hervey Bay        Queensland   \n","\n","     ...        Occupation Gender MaritalStatus HomeOwnerFlag NumberCarsOwned  \\\n","0    ...      Professional      M             M             1               0   \n","1    ...      Professional      M             S             0               1   \n","2    ...      Professional      M             M             1               1   \n","3    ...      Professional      F             S             0               1   \n","4    ...      Professional      F             S             1               4   \n","5    ...      Professional      M             S             1               1   \n","6    ...      Professional      F             S             1               1   \n","7    ...      Professional      M             M             1               2   \n","8    ...      Professional      F             S             1               3   \n","9    ...      Professional      M             S             0               1   \n","\n","  NumberChildrenAtHome TotalChildren YearlyIncome  AveMonthSpend  BikeBuyer  \n","0                    0             2       137947             89          0  \n","1                    3             3       101141            117          1  \n","2                    3             3        91945            123          0  \n","3                    0             0        86688             50          0  \n","4                    5             5        92771             95          1  \n","5                    0             0       103199             78          1  \n","6                    0             0        84756             54          1  \n","7                    3             3       109759            130          1  \n","8                    4             4        88005             85          1  \n","9                    0             0       106399             74          0  \n","\n","[10 rows x 25 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"tUOKBpu6-oKS","colab_type":"code","outputId":"1d489309-579e-490b-be6a-2e34843ab5ea","executionInfo":{"status":"ok","timestamp":1552913962530,"user_tz":-180,"elapsed":2427,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"cell_type":"code","source":["#Now we can further analyse the data! \n","#We want to identify the group of customers that account for the highest Average Monthly Spend:\n","#What are the max values for each gender?\n","print(IntegratedCustomerData.groupby(['Gender'])['AveMonthSpend'].max())\n","print(' ')\n","\n","#To get the age of each customer, we first have to convert the BirthDate series into datetime format.\n","IntegratedCustomerData['BirthDate'] = pd.to_datetime(IntegratedCustomerData['BirthDate'])\n","#Next, we calculate the age of each customer and create a new series called Age:\n","Age = np.array((IntegratedCustomerData['BirthDate'].dt.year - 1998))\n","Age = np.abs(Age)\n","IntegratedCustomerData['Age'] = Age\n","\n","#To get the age of each customer, we first have to convert the BirthDate series into datetime format.\n","TestData['BirthDate'] = pd.to_datetime(TestData['BirthDate'])\n","#Next, we calculate the age of each customer and create a new series called Age:\n","Age2 = np.array((TestData['BirthDate'].dt.year - 1998))\n","Age2 = np.abs(Age2)\n","TestData['Age'] = Age2"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Gender\n","F    114\n","M    176\n","Name: AveMonthSpend, dtype: int64\n"," \n"],"name":"stdout"}]},{"metadata":{"id":"KWXP-qBrJoQV","colab_type":"text"},"cell_type":"markdown","source":["In this section, we now turn our attention to the AveMonthSpend metric:\n"]},{"metadata":{"id":"AZ9y7_3eJvOI","colab_type":"code","outputId":"72097606-5ca3-4bd4-e558-88f5acf7dd43","executionInfo":{"status":"ok","timestamp":1552913962541,"user_tz":-180,"elapsed":2385,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/","height":586}},"cell_type":"code","source":["print(IntegratedCustomerData.groupby(['MaritalStatus'])['AveMonthSpend'].median())\n","print(' ')\n","print(IntegratedCustomerData.groupby(['Gender'])['AveMonthSpend'].median())\n","print(' ')\n","print(IntegratedCustomerData.groupby(['NumberCarsOwned'])['AveMonthSpend'].median())\n","print(' ')\n","print(IntegratedCustomerData.groupby(['Gender'])['AveMonthSpend'].var())\n","print(' ')\n","print(IntegratedCustomerData.groupby(['NumberChildrenAtHome'])['AveMonthSpend'].median())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["MaritalStatus\n","M    74\n","S    62\n","Name: AveMonthSpend, dtype: int64\n"," \n","Gender\n","F    52\n","M    79\n","Name: AveMonthSpend, dtype: int64\n"," \n","NumberCarsOwned\n","0     65\n","1     63\n","2     64\n","3     92\n","4    100\n","Name: AveMonthSpend, dtype: int64\n"," \n","Gender\n","F    269.723488\n","M    727.487022\n","Name: AveMonthSpend, dtype: float64\n"," \n","NumberChildrenAtHome\n","0     57.0\n","1     68.0\n","2     79.0\n","3     89.5\n","4    101.0\n","5    110.0\n","Name: AveMonthSpend, dtype: float64\n"],"name":"stdout"}]},{"metadata":{"id":"7lAHfgieMOUh","colab_type":"text"},"cell_type":"markdown","source":["And we also evaluate the BikeBuyer metric more closely."]},{"metadata":{"id":"tw30wLGZMeUZ","colab_type":"code","outputId":"22c3214b-70bf-4586-bbe5-6594ad463a07","executionInfo":{"status":"ok","timestamp":1552913962551,"user_tz":-180,"elapsed":2365,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/","height":513}},"cell_type":"code","source":["print(IntegratedCustomerData.groupby(['BikeBuyer'])['YearlyIncome'].median())\n","print(' ')\n","print(IntegratedCustomerData.groupby(['BikeBuyer'])['NumberCarsOwned'].median())\n","print(' ')\n","print(IntegratedCustomerData.groupby(['Occupation'])['BikeBuyer'].count())\n","print(' ')\n","print(IntegratedCustomerData.groupby(['Gender'])['BikeBuyer'].count())\n","print(' ')\n","print(IntegratedCustomerData.groupby(['MaritalStatus'])['BikeBuyer'].count())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["BikeBuyer\n","0    65955.5\n","1    96122.0\n","Name: YearlyIncome, dtype: float64\n"," \n","BikeBuyer\n","0    1\n","1    2\n","Name: NumberCarsOwned, dtype: int64\n"," \n","Occupation\n","Clerical          2619\n","Management        2734\n","Manual            2138\n","Professional      4963\n","Skilled Manual    4065\n","Name: BikeBuyer, dtype: int64\n"," \n","Gender\n","F    8168\n","M    8351\n","Name: BikeBuyer, dtype: int64\n"," \n","MaritalStatus\n","M    8917\n","S    7602\n","Name: BikeBuyer, dtype: int64\n"],"name":"stdout"}]},{"metadata":{"id":"PfDdGYcFlN8r","colab_type":"text"},"cell_type":"markdown","source":["# Challenge 2: Classification\n","\n","To complete this challenge:\n","\n","1.   Use the Adventure Works Cycles customer data you worked with in challenge 1 to create a classification model that predicts whether or not a customer will purchase a bike. The model should predict bike purchasing for new customers for whom no information about average monthly spend or previous bike purchases is available.\n","\n","2.   Download the test data. This data includes customer features but does not include bike purchasing or average monthly spend values.\n","\n","3.   Use your model to predict the corresponding test dataset. Don't forget to apply what you've learned throughout this course.\n","\n","\n","\n"]},{"metadata":{"id":"qX20xPpHmpdD","colab_type":"text"},"cell_type":"markdown","source":["## Meeting Challenge 2\n","\n","To meet this challenge, we first import any additional packages required, then load the additional data"]},{"metadata":{"id":"ORUdwRz1nqtc","colab_type":"code","outputId":"78fc3dce-90b1-450f-bfc1-5d395f18bf08","executionInfo":{"status":"ok","timestamp":1552913963617,"user_tz":-180,"elapsed":3357,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/"}},"cell_type":"code","source":["#Importing additional packages...\n","import seaborn as sns\n","import numpy.random as nr\n","import math\n","from sklearn import preprocessing\n","import sklearn.model_selection as ms\n","from sklearn import linear_model\n","import sklearn.metrics as sklm\n","\n","#Now let's examine the data\n","IntegratedCustomerData.head(5)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CustomerID</th>\n","      <th>Title</th>\n","      <th>FirstName</th>\n","      <th>MiddleName</th>\n","      <th>LastName</th>\n","      <th>Suffix</th>\n","      <th>AddressLine1</th>\n","      <th>AddressLine2</th>\n","      <th>City</th>\n","      <th>StateProvinceName</th>\n","      <th>...</th>\n","      <th>Gender</th>\n","      <th>MaritalStatus</th>\n","      <th>HomeOwnerFlag</th>\n","      <th>NumberCarsOwned</th>\n","      <th>NumberChildrenAtHome</th>\n","      <th>TotalChildren</th>\n","      <th>YearlyIncome</th>\n","      <th>AveMonthSpend</th>\n","      <th>BikeBuyer</th>\n","      <th>Age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11000</td>\n","      <td>NaN</td>\n","      <td>Jon</td>\n","      <td>V</td>\n","      <td>Yang</td>\n","      <td>NaN</td>\n","      <td>3761 N. 14th St</td>\n","      <td>NaN</td>\n","      <td>Rockhampton</td>\n","      <td>Queensland</td>\n","      <td>...</td>\n","      <td>M</td>\n","      <td>M</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>137947</td>\n","      <td>89</td>\n","      <td>0</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11001</td>\n","      <td>NaN</td>\n","      <td>Eugene</td>\n","      <td>L</td>\n","      <td>Huang</td>\n","      <td>NaN</td>\n","      <td>2243 W St.</td>\n","      <td>NaN</td>\n","      <td>Seaford</td>\n","      <td>Victoria</td>\n","      <td>...</td>\n","      <td>M</td>\n","      <td>S</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>101141</td>\n","      <td>117</td>\n","      <td>1</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11002</td>\n","      <td>NaN</td>\n","      <td>Ruben</td>\n","      <td>NaN</td>\n","      <td>Torres</td>\n","      <td>NaN</td>\n","      <td>5844 Linden Land</td>\n","      <td>NaN</td>\n","      <td>Hobart</td>\n","      <td>Tasmania</td>\n","      <td>...</td>\n","      <td>M</td>\n","      <td>M</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>91945</td>\n","      <td>123</td>\n","      <td>0</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11003</td>\n","      <td>NaN</td>\n","      <td>Christy</td>\n","      <td>NaN</td>\n","      <td>Zhu</td>\n","      <td>NaN</td>\n","      <td>1825 Village Pl.</td>\n","      <td>NaN</td>\n","      <td>North Ryde</td>\n","      <td>New South Wales</td>\n","      <td>...</td>\n","      <td>F</td>\n","      <td>S</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>86688</td>\n","      <td>50</td>\n","      <td>0</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11004</td>\n","      <td>NaN</td>\n","      <td>Elizabeth</td>\n","      <td>NaN</td>\n","      <td>Johnson</td>\n","      <td>NaN</td>\n","      <td>7553 Harness Circle</td>\n","      <td>NaN</td>\n","      <td>Wollongong</td>\n","      <td>New South Wales</td>\n","      <td>...</td>\n","      <td>F</td>\n","      <td>S</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>92771</td>\n","      <td>95</td>\n","      <td>1</td>\n","      <td>30</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 26 columns</p>\n","</div>"],"text/plain":["   CustomerID Title  FirstName MiddleName LastName Suffix  \\\n","0       11000   NaN        Jon          V     Yang    NaN   \n","1       11001   NaN     Eugene          L    Huang    NaN   \n","2       11002   NaN      Ruben        NaN   Torres    NaN   \n","3       11003   NaN    Christy        NaN      Zhu    NaN   \n","4       11004   NaN  Elizabeth        NaN  Johnson    NaN   \n","\n","          AddressLine1 AddressLine2         City StateProvinceName ...   \\\n","0      3761 N. 14th St          NaN  Rockhampton        Queensland ...    \n","1           2243 W St.          NaN      Seaford          Victoria ...    \n","2     5844 Linden Land          NaN       Hobart          Tasmania ...    \n","3     1825 Village Pl.          NaN   North Ryde   New South Wales ...    \n","4  7553 Harness Circle          NaN   Wollongong   New South Wales ...    \n","\n","  Gender MaritalStatus HomeOwnerFlag NumberCarsOwned NumberChildrenAtHome  \\\n","0      M             M             1               0                    0   \n","1      M             S             0               1                    3   \n","2      M             M             1               1                    3   \n","3      F             S             0               1                    0   \n","4      F             S             1               4                    5   \n","\n","  TotalChildren YearlyIncome AveMonthSpend  BikeBuyer  Age  \n","0             2       137947            89          0   32  \n","1             3       101141           117          1   33  \n","2             3        91945           123          0   33  \n","3             0        86688            50          0   30  \n","4             5        92771            95          1   30  \n","\n","[5 rows x 26 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"metadata":{"id":"WU4o2rVD2bmT","colab_type":"text"},"cell_type":"markdown","source":["The next thing we will do is check for class imbalance in the IntegratedCustomerData..."]},{"metadata":{"id":"wy82hfj6whNc","colab_type":"code","outputId":"719ffe2f-4f0c-404d-c37c-88f30b349d29","executionInfo":{"status":"ok","timestamp":1552913963629,"user_tz":-180,"elapsed":3237,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/"}},"cell_type":"code","source":["#Upon checking for imbalance the following series stood out as moderately imbalanced\n","bikebuyer_counts1 = IntegratedCustomerData.groupby(['NumberChildrenAtHome'])['BikeBuyer'].count()\n","print(bikebuyer_counts1)\n","print(' ')\n","\n","bikebuyer_counts2 = IntegratedCustomerData.groupby(['HomeOwnerFlag'])['BikeBuyer'].count()\n","print(bikebuyer_counts2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["NumberChildrenAtHome\n","0    9990\n","1    2197\n","2    1462\n","3    1066\n","4     952\n","5     852\n","Name: BikeBuyer, dtype: int64\n"," \n","HomeOwnerFlag\n","0     5387\n","1    11132\n","Name: BikeBuyer, dtype: int64\n"],"name":"stdout"}]},{"metadata":{"id":"IjrDeBtFzWdH","colab_type":"text"},"cell_type":"markdown","source":["And then we can drop columns that contain Nan values"]},{"metadata":{"id":"pcCy7_Epzehs","colab_type":"code","outputId":"08bc59ac-b553-43b2-ef77-3e24fea6676a","executionInfo":{"status":"ok","timestamp":1552913963635,"user_tz":-180,"elapsed":3200,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/"}},"cell_type":"code","source":["TrainData = IntegratedCustomerData.drop(['Title'], axis = 1)\n","TrainData = TrainData.drop(['MiddleName'], axis = 1)\n","TrainData = TrainData.drop(['Suffix'], axis = 1)\n","TrainData = TrainData.drop(['AddressLine2'], axis = 1)\n","\n","TestData = TestData.drop(['Title'], axis = 1)\n","TestData = TestData.drop(['MiddleName'], axis = 1)\n","TestData = TestData.drop(['Suffix'], axis = 1)\n","TestData = TestData.drop(['AddressLine2'], axis = 1)\n","\n","print(TrainData.shape)\n","print(TestData.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(16519, 22)\n","(500, 20)\n"],"name":"stdout"}]},{"metadata":{"id":"AU6knbpsd0E9","colab_type":"text"},"cell_type":"markdown","source":["From this point, because we want our number of features to be nice and lean, we drop the descriptive data that came with the original dataframe."]},{"metadata":{"id":"Me_slU2weLVp","colab_type":"code","outputId":"951be89a-11eb-475f-a6ed-e5ba80df1b19","executionInfo":{"status":"ok","timestamp":1552913963644,"user_tz":-180,"elapsed":3129,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/"}},"cell_type":"code","source":["TrainData = TrainData.drop(['FirstName'], axis = 1)\n","TrainData = TrainData.drop(['LastName'], axis = 1)\n","TrainData = TrainData.drop(['AddressLine1'], axis = 1)\n","TrainData = TrainData.drop(['City'], axis = 1)\n","TrainData = TrainData.drop(['StateProvinceName'], axis = 1)\n","TrainData = TrainData.drop(['CountryRegionName'], axis = 1)\n","TrainData = TrainData.drop(['PostalCode'], axis = 1)\n","TrainData = TrainData.drop(['PhoneNumber'], axis = 1)\n","TrainData = TrainData.drop(['BirthDate'], axis = 1)\n","\n","TestData = TestData.drop(['FirstName'], axis = 1)\n","TestData = TestData.drop(['LastName'], axis = 1)\n","TestData = TestData.drop(['AddressLine1'], axis = 1)\n","TestData = TestData.drop(['City'], axis = 1)\n","TestData = TestData.drop(['StateProvinceName'], axis = 1)\n","TestData = TestData.drop(['CountryRegionName'], axis = 1)\n","TestData = TestData.drop(['PostalCode'], axis = 1)\n","TestData = TestData.drop(['PhoneNumber'], axis = 1)\n","TestData = TestData.drop(['BirthDate'], axis = 1)\n","\n","\n","print(TrainData.shape)\n","print(TestData.shape)\n","print(' ')\n","TrainData.head()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(16519, 13)\n","(500, 11)\n"," \n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CustomerID</th>\n","      <th>Education</th>\n","      <th>Occupation</th>\n","      <th>Gender</th>\n","      <th>MaritalStatus</th>\n","      <th>HomeOwnerFlag</th>\n","      <th>NumberCarsOwned</th>\n","      <th>NumberChildrenAtHome</th>\n","      <th>TotalChildren</th>\n","      <th>YearlyIncome</th>\n","      <th>AveMonthSpend</th>\n","      <th>BikeBuyer</th>\n","      <th>Age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11000</td>\n","      <td>Bachelors</td>\n","      <td>Professional</td>\n","      <td>M</td>\n","      <td>M</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>137947</td>\n","      <td>89</td>\n","      <td>0</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11001</td>\n","      <td>Bachelors</td>\n","      <td>Professional</td>\n","      <td>M</td>\n","      <td>S</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>101141</td>\n","      <td>117</td>\n","      <td>1</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11002</td>\n","      <td>Bachelors</td>\n","      <td>Professional</td>\n","      <td>M</td>\n","      <td>M</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>91945</td>\n","      <td>123</td>\n","      <td>0</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11003</td>\n","      <td>Bachelors</td>\n","      <td>Professional</td>\n","      <td>F</td>\n","      <td>S</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>86688</td>\n","      <td>50</td>\n","      <td>0</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11004</td>\n","      <td>Bachelors</td>\n","      <td>Professional</td>\n","      <td>F</td>\n","      <td>S</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>92771</td>\n","      <td>95</td>\n","      <td>1</td>\n","      <td>30</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   CustomerID   Education    Occupation Gender MaritalStatus  HomeOwnerFlag  \\\n","0       11000  Bachelors   Professional      M             M              1   \n","1       11001  Bachelors   Professional      M             S              0   \n","2       11002  Bachelors   Professional      M             M              1   \n","3       11003  Bachelors   Professional      F             S              0   \n","4       11004  Bachelors   Professional      F             S              1   \n","\n","   NumberCarsOwned  NumberChildrenAtHome  TotalChildren  YearlyIncome  \\\n","0                0                     0              2        137947   \n","1                1                     3              3        101141   \n","2                1                     3              3         91945   \n","3                1                     0              0         86688   \n","4                4                     5              5         92771   \n","\n","   AveMonthSpend  BikeBuyer  Age  \n","0             89          0   32  \n","1            117          1   33  \n","2            123          0   33  \n","3             50          0   30  \n","4             95          1   30  "]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"Tvouxj6FeDfI","colab_type":"text"},"cell_type":"markdown","source":["Now feature engineering can begin!! Actually, we already did this when we calculated the Age series using birthdate information  - we can now do this for the test data as well. We continue by creating dummy variables for all the series that contain categorical data as shown:"]},{"metadata":{"id":"JsgYHHX9gZCC","colab_type":"code","outputId":"56b0ee0c-6959-4b55-b24b-55add6da8df0","executionInfo":{"status":"ok","timestamp":1552913963648,"user_tz":-180,"elapsed":3103,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/"}},"cell_type":"code","source":["#We can then encode our categorical variables into dummy variables\n","#First we start with Marital Status, by creating the dummy variables that correspond to its categories\n","TrainData['MaritalStatus_Married'] = TrainData.MaritalStatus.map({'M': 1, 'S': 0})\n","TrainData['MaritalStatus_Single'] = TrainData.MaritalStatus.map({'M': 0, 'S': 1})\n","\n","TestData['MaritalStatus_Married'] = TestData.MaritalStatus.map({'M': 1, 'S': 0})\n","TestData['MaritalStatus_Single'] = TestData.MaritalStatus.map({'M': 0, 'S': 1})\n","\n","\n","#We repeat the process for Gender:\n","TrainData['Gender_Male'] = TrainData.Gender.map({'M': 1, 'F': 0})\n","TrainData['Gender_Female'] = TrainData.Gender.map({'M': 0, 'F': 1})\n","\n","TestData['Gender_Male'] = TestData.Gender.map({'M': 1, 'F': 0})\n","TestData['Gender_Female'] = TestData.Gender.map({'M': 0, 'F': 1})\n","\n","\n","#Then for Education:\n","education_dummies1 = pd.get_dummies(TrainData.Education)\n","TrainData = pd.concat([TrainData, education_dummies1], axis = 1)\n","\n","education_dummies2 = pd.get_dummies(TestData.Education)\n","TestData = pd.concat([TestData, education_dummies2], axis = 1)\n","\n","#And finally for Occupation:\n","occupation_dummies1 = pd.get_dummies(TrainData.Occupation)\n","TrainData = pd.concat([TrainData, occupation_dummies1], axis = 1)\n","\n","occupation_dummies2 = pd.get_dummies(TestData.Occupation)\n","TestData = pd.concat([TestData, occupation_dummies2], axis = 1)\n","\n","print(TrainData.shape)\n","print(TestData.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(16519, 27)\n","(500, 25)\n"],"name":"stdout"}]},{"metadata":{"id":"3Bt6UdCkzzX_","colab_type":"text"},"cell_type":"markdown","source":["We need to rename the dummy variable series' names to identify which column they came from."]},{"metadata":{"id":"iYJmmiLw0A5D","colab_type":"code","outputId":"36307ee4-0373-4fd8-ca59-961a0f5ec452","executionInfo":{"status":"ok","timestamp":1552913963657,"user_tz":-180,"elapsed":3067,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/"}},"cell_type":"code","source":["#for Education\n","TrainData.columns = [str.replace('Bachelors', 'Education_Bachelors') for str in TrainData.columns]\n","TrainData.columns = [str.replace('Graduate Degree', 'Education_Graduate') for str in TrainData.columns]\n","TrainData.columns = [str.replace('High School', 'Education_HS') for str in TrainData.columns]\n","TrainData.columns = [str.replace('Partial College', 'Education_PartialCollege') for str in TrainData.columns]\n","TrainData.columns = [str.replace('Partial High School', 'Education_PartialHS') for str in TrainData.columns]\n","\n","TestData.columns = [str.replace('Bachelors', 'Education_Bachelors') for str in TestData.columns]\n","TestData.columns = [str.replace('Graduate Degree', 'Education_Graduate') for str in TestData.columns]\n","TestData.columns = [str.replace('High School', 'Education_HS') for str in TestData.columns]\n","TestData.columns = [str.replace('Partial College', 'Education_PartialCollege') for str in TestData.columns]\n","TestData.columns = [str.replace('Partial High School', 'Education_PartialHS') for str in TestData.columns]\n","\n","#and Occupation.\n","TrainData.columns = [str.replace('Clerical', 'Occupation_Clerical') for str in TrainData.columns]\n","TrainData.columns = [str.replace('Management', 'Occupation_Management') for str in TrainData.columns]\n","TrainData.columns = [str.replace('Manual', 'Occupation_Manual') for str in TrainData.columns]\n","TrainData.columns = [str.replace('Professional', 'Occupation_Professional') for str in TrainData.columns]\n","TrainData.columns = [str.replace('Skilled Manual', 'Occupation_SM') for str in TrainData.columns]\n","\n","TestData.columns = [str.replace('Clerical', 'Occupation_Clerical') for str in TestData.columns]\n","TestData.columns = [str.replace('Management', 'Occupation_Management') for str in TestData.columns]\n","TestData.columns = [str.replace('Manual', 'Occupation_Manual') for str in TestData.columns]\n","TestData.columns = [str.replace('Professional', 'Occupation_Professional') for str in TestData.columns]\n","TestData.columns = [str.replace('Skilled Manual', 'Occupation_SM') for str in TestData.columns]\n","\n","print(TrainData.shape)\n","print(TestData.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(16519, 27)\n","(500, 25)\n"],"name":"stdout"}]},{"metadata":{"id":"j8B8-c8H4qK3","colab_type":"text"},"cell_type":"markdown","source":["Now that we have our dummy variables, we can now remove the original columns! It would probably be a good idea to also remove the CustomerID series at this point..."]},{"metadata":{"id":"enL5nGXv4zvV","colab_type":"code","outputId":"1bd666a1-cc27-4c43-f60a-ad656cc503b3","executionInfo":{"status":"ok","timestamp":1552913964091,"user_tz":-180,"elapsed":3478,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/"}},"cell_type":"code","source":["TrainData = TrainData.drop(['Education'], axis = 1)\n","TrainData = TrainData.drop(['Occupation'], axis = 1)\n","TrainData = TrainData.drop(['Gender'], axis = 1)\n","TrainData = TrainData.drop(['MaritalStatus'], axis = 1)\n","TrainData = TrainData.drop(['CustomerID'], axis = 1)\n","\n","TestData = TestData.drop(['Education'], axis = 1)\n","TestData = TestData.drop(['Occupation'], axis = 1)\n","TestData = TestData.drop(['Gender'], axis = 1)\n","TestData = TestData.drop(['MaritalStatus'], axis = 1)\n","TestData = TestData.drop(['CustomerID'], axis = 1)\n","\n","print(TrainData.shape)\n","print(TestData.shape)\n","\n","#save to Excel\n","from google.colab import files\n","TestData.to_excel('AW_PreppedTestData.xlsx')\n","\n","#files.download('AW_PreppedTestData.xlsx')#"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(16519, 22)\n","(500, 20)\n"],"name":"stdout"}]},{"metadata":{"id":"bzLI25dHA86M","colab_type":"text"},"cell_type":"markdown","source":["With all this preprocessing done, it is time to separate the label (BikeBuyer) and AveMonthSpend from the features."]},{"metadata":{"id":"U-NPu4MqBKVm","colab_type":"code","outputId":"af7cad51-25c6-409a-96f7-8f38b7be4090","executionInfo":{"status":"ok","timestamp":1552913972930,"user_tz":-180,"elapsed":12291,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/"}},"cell_type":"code","source":["Label = TrainData['BikeBuyer']\n","Features = TrainData.drop(['BikeBuyer'], axis = 1)\n","Features = Features.drop(['AveMonthSpend'], axis = 1)\n","\n","print(Label.shape)\n","print(Features.shape)\n","print(TestData.shape)\n","\n","#save to Excel\n","from google.colab import files\n","Features.to_excel('AV_Features.xlsx')\n","\n","files.download('AV_Features.xlsx')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(16519,)\n","(16519, 20)\n","(500, 20)\n"],"name":"stdout"}]},{"metadata":{"id":"10MwmYtKC43F","colab_type":"text"},"cell_type":"markdown","source":["We can now scale the Features using StandardScaler and then use the resulting scale to scale the test data as shown:"]},{"metadata":{"id":"gBSExfVsC23z","colab_type":"code","outputId":"487f9392-0ce5-47dc-d0de-43fd6fa72c00","executionInfo":{"status":"ok","timestamp":1552913972951,"user_tz":-180,"elapsed":12244,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/"}},"cell_type":"code","source":["scaler = preprocessing.StandardScaler().fit(Features.iloc[:,19:])\n","Features.iloc[:,19:] = scaler.transform(Features.iloc[:,19:])\n","TestData.iloc[:,19:] = scaler.transform(TestData.iloc[:,19:])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8 were all converted to float64 by StandardScaler.\n","  return self.partial_fit(X, y)\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DataConversionWarning: Data with input dtype uint8 were all converted to float64 by StandardScaler.\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype uint8 were all converted to float64 by StandardScaler.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"}]},{"metadata":{"id":"7WeaWdzvaTz4","colab_type":"text"},"cell_type":"markdown","source":["With our values scaled for both training and testing datasets, let's build a logistic regression model!"]},{"metadata":{"id":"_z8jRvdRaiE7","colab_type":"code","outputId":"5a7262f3-ff49-469b-c6c2-bc3fcf34c96d","executionInfo":{"status":"ok","timestamp":1552913972961,"user_tz":-180,"elapsed":12231,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/"}},"cell_type":"code","source":["#First we compute our model\n","logistic_mod = linear_model.LogisticRegression() \n","logistic_mod.fit(Features,Label)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n","  FutureWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","          intercept_scaling=1, max_iter=100, multi_class='warn',\n","          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n","          tol=0.0001, verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":19}]},{"metadata":{"id":"Oi8duF3HfkLx","colab_type":"code","outputId":"88001514-bfb3-4e46-a391-596876602e67","executionInfo":{"status":"ok","timestamp":1552913972969,"user_tz":-180,"elapsed":12145,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/"}},"cell_type":"code","source":["#then we identify our coefficients and intercept\n","print(logistic_mod.intercept_)\n","print(logistic_mod.coef_)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[-0.01858827]\n","[[-1.55372032e-02  3.88399703e-02  3.82885877e-01  2.53339315e-01\n","   1.05828547e-05 -6.94886841e-02 -1.14073286e-01  9.54850140e-02\n","   3.30357451e-02 -5.16240171e-02  1.37489413e-02 -3.45595063e-02\n","   1.50677360e-04  8.41466343e-03 -6.34304789e-03 -3.93011025e-03\n","  -1.35062910e-02  5.48953500e-03  1.86762931e-02 -4.81593829e-02]]\n"],"name":"stdout"}]},{"metadata":{"id":"TBEjPNtPbiD1","colab_type":"text"},"cell_type":"markdown","source":["Will our model up and running, let's identify the class with the highest probability to make our predictions on the test data"]},{"metadata":{"id":"2JjNkh2bgtXZ","colab_type":"code","outputId":"932b26e5-28c1-4198-d881-67b575a70d7e","executionInfo":{"status":"ok","timestamp":1552913972982,"user_tz":-180,"elapsed":12088,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/"}},"cell_type":"code","source":["probabilities = logistic_mod.predict_proba(TestData)\n","print(probabilities[:9,:])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[0.79665473 0.20334527]\n"," [0.40900206 0.59099794]\n"," [0.92245319 0.07754681]\n"," [0.65801973 0.34198027]\n"," [0.71442923 0.28557077]\n"," [0.905003   0.094997  ]\n"," [0.41572415 0.58427585]\n"," [0.21488823 0.78511177]\n"," [0.34881316 0.65118684]]\n"],"name":"stdout"}]},{"metadata":{"id":"8RqjwSO5iE3L","colab_type":"text"},"cell_type":"markdown","source":["Finally, we get the actual scores/predictions made by our model below:"]},{"metadata":{"id":"KNJrFgFQiTbT","colab_type":"code","outputId":"a7336626-e7d4-4055-ab20-780fa8771efa","executionInfo":{"status":"ok","timestamp":1552913972987,"user_tz":-180,"elapsed":12067,"user":{"displayName":"C Thinwa","photoUrl":"","userId":"00369549388519870238"}},"colab":{"base_uri":"https://localhost:8080/"}},"cell_type":"code","source":["def score_model(probs, threshold):\n","    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n","scores = score_model(probabilities, 0.5)\n","Answer_array = np.array(scores[:500])\n","Answer = pd.DataFrame(Answer_array)\n","\n","#save to Excel\n","from google.colab import files\n","Answer.to_excel('Answer.xlsx')\n","\n","#files.download('Answer.xlsx')#\n","\n","Answer.head(10)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0\n","0  0\n","1  1\n","2  0\n","3  0\n","4  0\n","5  0\n","6  1\n","7  1\n","8  1\n","9  0"]},"metadata":{"tags":[]},"execution_count":22}]}]}